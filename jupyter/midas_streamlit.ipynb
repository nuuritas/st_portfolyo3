{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "you are using nologin method, data you access may be limited\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datetime import datetime as dt\n",
    "import os \n",
    "import json\n",
    "import requests\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "from tvDatafeed import TvDatafeed, Interval\n",
    "tv = TvDatafeed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sector_wide(data, sector_name):\n",
    "    rename_dict = {\n",
    "        \"Sektör Ortalamaları\": \"Metrics\",\n",
    "        \"F/K\": \"fk\",\n",
    "        \"PD/DD\": \"pd_dd\",\n",
    "        \"FD/FAVÖK\": \"fd_favok\"\n",
    "    }\n",
    "    \n",
    "    data = data.rename(columns=rename_dict)\n",
    "\n",
    "    \n",
    "    new_columns = {\n",
    "        \"BIST 100\": \"bist100\",\n",
    "        \"Aritmetik Ortalama\": \"ao\",\n",
    "        \"Ağırlıklı Ortalama\": \"wo\",\n",
    "        \"Medyan\": \"median\"\n",
    "    }\n",
    "\n",
    "    \n",
    "    wide_df = pd.DataFrame()\n",
    "    wide_df['sector_name'] = [sector_name]\n",
    "\n",
    "    for metric, prefix in new_columns.items():\n",
    "        for column in ['fk', 'pd_dd', 'fd_favok']:\n",
    "            col_name = f\"{prefix}_{column}\"\n",
    "            if sector_name == 'bankacilik' and column == 'fd_favok':\n",
    "                wide_df[col_name] = np.nan\n",
    "            else:\n",
    "                wide_df[col_name] = data[data['Metrics'] == metric][column].values\n",
    "\n",
    "    return wide_df\n",
    "\n",
    "# Function to convert 'Piyasa Değeri' to numerical value\n",
    "def convert_piyasa_degeri(value):\n",
    "    value = value.replace('₺', '').strip()\n",
    "    if 'mr' in value:\n",
    "        value = float(value.replace('mr', '')) * 1e3  # convert to billion\n",
    "    elif 'mn' in value:\n",
    "        value = float(value.replace('mn', ''))  # convert to million\n",
    "    return value\n",
    "\n",
    "def get_sector(sector_name):\n",
    "\n",
    "    headers = {\n",
    "        'authority': 'fintables.com',\n",
    "        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "        'accept-language': 'en-US,en;q=0.9,tr;q=0.8,tr-TR;q=0.7',\n",
    "        'cache-control': 'no-cache',\n",
    "        'cookie': '_gid=GA1.2.50961081.1690710140; _gcl_au=1.1.518997462.1690710149; auth-token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0b2tlbl90eXBlIjoiYWNjZXNzIiwiZXhwIjoyMTIyNzEwMTk3LCJpYXQiOjE2OTA3MTAxOTcsImp0aSI6IjQ2NGI0YTIxYjY3ZjQ3ZDY4MmEwYjg5NWE3ZjlkMWE4IiwidXNlcl9pZCI6MTEyNzMzfQ.Bh3945i5RjYHblFOyoN_e9oqVmQcOUukFo8GqXp5wtg; _gat_UA-72451211-3=1; _ga=GA1.2.1134893438.1690710140; _ga_22JQCWWZZJ=GS1.1.1690710149.1.1.1690711335.20.0.0',\n",
    "        'dnt': '1',\n",
    "        'pragma': 'no-cache',\n",
    "        'sec-ch-ua': '\"Not.A/Brand\";v=\"8\", \"Chromium\";v=\"114\", \"Google Chrome\";v=\"114\"',\n",
    "        'sec-ch-ua-mobile': '?0',\n",
    "        'sec-ch-ua-platform': '\"macOS\"',\n",
    "        'sec-fetch-dest': 'document',\n",
    "        'sec-fetch-mode': 'navigate',\n",
    "        'sec-fetch-site': 'same-origin',\n",
    "        'sec-fetch-user': '?1',\n",
    "        'upgrade-insecure-requests': '1',\n",
    "        'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    response = requests.get(f'https://fintables.com/sektorler/{sector_name}', headers=headers)\n",
    "\n",
    "    # The content of the response\n",
    "    from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    sektor_ozet = soup.find_all('table', class_=\"min-w-full\")[0]\n",
    "    sektor_ozet2 = str(sektor_ozet).replace(\".\",\"\").replace(',', '.')\n",
    "    sektor_ozet_df = pd.read_html(str(sektor_ozet2))[0]\n",
    "    sektor_ozet_wide = convert_sector_wide(sektor_ozet_df, sector_name)\n",
    "    \n",
    "    my_table = soup.find_all('table', class_=\"min-w-full\")[1]\n",
    "    my_table2 = str(my_table).replace(\".\",\"\").replace(',', '.')\n",
    "    df = pd.read_html(str(my_table2))[0]\n",
    "    \n",
    "    df['Piyasa Değeri'] = df['Piyasa Değeri'].apply(convert_piyasa_degeri)\n",
    "    #df['Piyasa Değeri'] = df['Piyasa Değeri'].astype(int)\n",
    "    df[\"sector\"] = sector_name\n",
    "\n",
    "    return sektor_ozet_wide, df\n",
    "\n",
    "def get_sector_multiple(sector_names):\n",
    "    ozet_list = []\n",
    "    sirket_list = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        for sektor_ozet,tum_sirketler in tqdm(executor.map(get_sector, sector_names), total=len(sector_names), desc=\"Fintables Şirketler\"):\n",
    "            try:\n",
    "                sirket_list.append(tum_sirketler)\n",
    "                ozet_list.append(sektor_ozet)\n",
    "            except Exception as e:\n",
    "                print(\"Error: \", e)\n",
    "    sirket_df = pd.concat(sirket_list, axis=0, ignore_index=True)\n",
    "    ozet_df = pd.concat(ozet_list, axis=0, ignore_index=True)\n",
    "\n",
    "    sirket_df['Şirket Kodu'] = sirket_df['Şirket Kodu'].str[:-7]\n",
    "    # sirket_df['Piyasa Değeri'] = sirket_df['Piyasa Değeri'].astype(float)\n",
    "\n",
    "    sirket_df.columns = ['sirket_kodu', 'piyasa_degeri', 'fk', 'pd_dd', 'fd_favok', 'sector']\n",
    "    return ozet_df, sirket_df\n",
    "\n",
    "sector_names = json.load(open('sector_names.json',encoding=\"utf-8\"))\n",
    "\n",
    "print(\"Fintables Sektörler ve Şirketler Güncelleniyor\")\n",
    "ozet_df, sirket_df = get_sector_multiple(sector_names)\n",
    "\n",
    "all_tickers = sirket_df['sirket_kodu'].unique()\n",
    "all_tickers = list(all_tickers[:10])\n",
    "all_tickers.append('XU100')\n",
    "data_list = []\n",
    "\n",
    "def fetch_data(ticker):\n",
    "    data = tv.get_hist(symbol=ticker, exchange='BIST', interval=Interval.in_daily, n_bars=200)\n",
    "    return data\n",
    "\n",
    "# Use a ThreadPoolExecutor to fetch data in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    # Wrap the executor and the ticker list with tqdm for a progress bar\n",
    "    data_list = list(tqdm(executor.map(fetch_data, all_tickers), total=len(all_tickers)))\n",
    "\n",
    "\n",
    "data = pd.concat(data_list).reset_index()\n",
    "data[\"symbol\"] = data[\"symbol\"].str[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_no_sell(grouped):\n",
    "    grouped.insert(2,\"d_q_s\", 0)\n",
    "    grouped.insert(3,\"d_q_c\",grouped[\"d_q_b\"] - grouped[\"d_q_s\"])\n",
    "    grouped.insert(5,\"d_a_s\",0)\n",
    "    grouped[\"d_p_s\"] = 0\n",
    "\n",
    "    grouped = grouped.fillna(0)\n",
    "    grouped[\"h_q\"] = grouped[\"d_q_c\"].cumsum()\n",
    "    \n",
    "\n",
    "    grouped[\"a_a_b\"] = grouped[\"d_a_b\"].cumsum() \n",
    "    grouped[\"a_a_s\"] = grouped[\"d_a_s\"].cumsum() \n",
    "\n",
    "    grouped[\"a_p_b\"] = grouped[\"a_a_b\"] / grouped[\"h_q\"]\n",
    "\n",
    "    grouped[\"a_p_b\"] = grouped[\"a_p_b\"].apply(lambda x: round(x,2))\n",
    "    grouped[\"d_r_p\"] = 0\n",
    "    grouped[\"a_r_p\"] = 0\n",
    "    grouped.insert(9,\"h_a\",grouped[\"a_p_b\"] * grouped[\"h_q\"])\n",
    "    grouped[\"h_a\"] = grouped[\"h_a\"].apply(lambda x: round(x,2))\n",
    "    return grouped\n",
    "\n",
    "def p_buy_and_sell(grouped):\n",
    "    grouped = grouped.fillna(0)\n",
    "    grouped.insert(3,\"d_q_c\",grouped[\"d_q_b\"] - grouped[\"d_q_s\"])\n",
    "    grouped[\"h_q\"] = grouped[\"d_q_c\"].cumsum()\n",
    "    \n",
    "\n",
    "    grouped[\"a_a_b\"] = grouped[\"d_a_b\"].cumsum() \n",
    "    grouped[\"a_a_s\"] = grouped[\"d_a_s\"].cumsum() \n",
    "\n",
    "    grouped.loc[0,\"a_p_b\"] = grouped.loc[0,\"a_a_b\"] / grouped.loc[0,\"h_q\"]\n",
    "\n",
    "    for i, val in grouped.iterrows():\n",
    "        #Eğer tüm hisseler o gün satıldıysa, bir sonraki gündeki ortalama fiyat sadece yeni alınan hisselerin ortalaması olur.\n",
    "        #Eğer tüm hisseler o gün satıldıysa, ve o gün alım olmadıysa, ortalama önceki güne eşit olur.\n",
    "        if val[\"h_q\"] == 0:\n",
    "            if val[\"d_q_b\"] == 0:\n",
    "                grouped.loc[i,\"a_p_b\"] = grouped.loc[i-1,\"a_p_b\"]\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            #Eğer alış olmadıysa, eldeki maliyet değişmez.\n",
    "            if val[\"d_q_b\"] == 0:\n",
    "                grouped.loc[i,\"a_p_b\"] = grouped.loc[i-1,\"a_p_b\"]\n",
    "            else:\n",
    "                grouped.loc[i,\"a_p_b\"] = (grouped.loc[:i,\"d_a_b\"].sum() - grouped.loc[:i,\"d_a_s\"].sum()) / grouped.loc[i,\"h_q\"]\n",
    "            # grouped.loc[i,\"a_p_b\"] = val[\"a_a_b\"] / val[\"h_q\"]\n",
    "        if 0 in grouped.loc[:i,\"h_q\"].values:\n",
    "            \n",
    "            last_zero_index = grouped.loc[:i,\"h_q\"].tolist().index(0)\n",
    "            if val[\"d_q_b\"] != 0:\n",
    "                grouped.loc[i,\"a_p_b\"] = sum_product = grouped.loc[last_zero_index:i, \n",
    "                                        \"d_p_b\"].mul(grouped.loc[last_zero_index:i, \"d_q_b\"]).sum() / grouped.loc[last_zero_index:i,\"d_q_b\"].sum()\n",
    "        if val[\"d_q_s\"] > 0:\n",
    "            last_average_buy = grouped.loc[:i].query(\"d_p_b != 0\")[\"d_p_b\"].iloc[-1]\n",
    "            grouped.loc[i,\"d_r_p\"] = (val[\"d_p_s\"] - last_average_buy) * val[\"d_q_s\"]\n",
    "        else:\n",
    "            grouped.loc[i,\"d_r_p\"] = 0\n",
    "        grouped.loc[i,\"a_r_p\"] = grouped.loc[:i,\"d_r_p\"].sum()\n",
    "    \n",
    "    grouped[\"a_p_b\"] = grouped[\"a_p_b\"].apply(lambda x: round(x,2))\n",
    "        \n",
    "    grouped.insert(9,\"h_a\",grouped[\"a_p_b\"] * grouped[\"h_q\"])\n",
    "    grouped[\"h_a\"] = grouped[\"h_a\"].apply(lambda x: round(x,2))\n",
    "    return grouped\n",
    "\n",
    "def port_func1(ticker,df):\n",
    "    data = df.query(\"ticker == @ticker\")\n",
    "    data[\"date\"] = data[\"date\"].apply(lambda x: x.normalize())\n",
    "\n",
    "    df1 = data.groupby([\"date\", \"buy_sell\"]).agg({\n",
    "        \"quantity\": \"sum\",\n",
    "        \"trans_amount\": \"sum\",\n",
    "        \"price\": lambda x: (x * data.loc[x.index, \"quantity\"]).sum() / df.loc[x.index, \"quantity\"].sum()\n",
    "    }).unstack()\n",
    "\n",
    "    df1.columns = [\"_\".join(col).strip() for col in df1.columns.values]\n",
    "    df1 = df1.rename(columns={\n",
    "        \"quantity_Alış\": \"d_q_b\",\n",
    "        \"quantity_Satış\": \"d_q_s\",\n",
    "        \"trans_amount_Alış\": \"d_a_b\",\n",
    "        \"trans_amount_Satış\": \"d_a_s\",\n",
    "        \"price_Alış\": \"d_p_b\",\n",
    "        \"price_Satış\": \"d_p_s\"\n",
    "    }).reset_index()\n",
    "\n",
    "    ####Situation stock never sold:\n",
    "    if \"d_q_s\" not in df1.columns:\n",
    "        df2 = p_no_sell(df1)\n",
    "    else:\n",
    "        df2 = p_buy_and_sell(df1)\n",
    "    return ticker, df2\n",
    "\n",
    "    ticker, df3 = port_func1(ticker,df)\n",
    "\n",
    "def port_func2(ticker,df3):\n",
    "        min_date = df3[\"date\"].min()\n",
    "        if df3.loc[len(df3)-1,\"h_q\"] != 0:\n",
    "            max_date = dt.today()\n",
    "        else:\n",
    "            max_date = df3[\"date\"].max()\n",
    "        df4 = pd.DataFrame({'date': pd.date_range(start=min_date, end=max_date, freq='B').normalize()})\n",
    "        df4 = df4.merge(df3, on='date', how='left')\n",
    "        df4 = df4.fillna({\n",
    "                'd_q_b': 0,\n",
    "                'd_q_s': 0,\n",
    "                'd_a_b': 0,\n",
    "                'd_a_s': 0,\n",
    "                'd_p_b': 0,\n",
    "                'd_p_s': 0,\n",
    "                'd_q_c': 0,\n",
    "                \"d_r_p\": 0,\n",
    "            })\n",
    "        \n",
    "        df4 = df4.merge(tvdata.query(\"ticker == @ticker\")[[\"date\",\"open\",\"close\"]], on=[\"date\"],how=\"left\")\n",
    "        f_fill_col = [\"h_q\", \"a_a_b\",\"a_a_s\", \"a_p_b\", \"a_r_p\",\"close\",\"open\"] \n",
    "        #min, max, vol_ö\n",
    "        df4[f_fill_col] = df4[f_fill_col].ffill()\n",
    "        \n",
    "        df4 = df4.query(\"d_q_b + d_q_s + h_q > 0\")\n",
    "        # df4 = df4.fillna(0)\n",
    "        df4[\"h_a\"] = df4[\"h_q\"] * df4[\"a_p_b\"]\n",
    "        df4['t_v'] = df4['h_q'] * df4['close']\n",
    "        \n",
    "        df4['a_ur_p'] = df4['t_v'] - df4['h_a']\n",
    "        df4['a_ur_p'] = np.where(df4['h_q'] == 0, 0, df4['a_ur_p'])\n",
    "        df4[\"d_ur_p\"] = (df4[\"close\"] - df4[\"open\"]) * df4[\"h_q\"]\n",
    "        df4[\"d_p\"] = df4[\"d_ur_p\"] + df4[\"d_r_p\"]\n",
    "        df4[\"a_p\"] = df4[\"a_ur_p\"] + df4[\"a_r_p\"]\n",
    "        df4[\"d_%\"] = (round(df4[\"close\"] / df4[\"open\"],3) - 1) * 100\n",
    "        df4[\"a_%\"] = (round(df4[\"close\"] / df4[\"a_p_b\"],3) - 1) * 100\n",
    "        df4.reset_index(drop=True, inplace=True)\n",
    "        df4[\"d_p_b\"] = df4[\"d_p_b\"].apply(lambda x: round(x,2))\n",
    "        df4[\"open\"] = df4[\"open\"].apply(lambda x: round(x,2))\n",
    "        df4.insert(1, 'ticker', ticker)\n",
    "        return df4    \n",
    "    \n",
    "def portfoy(ticker):\n",
    "    ticker, df3 = port_func1(ticker,df)\n",
    "    df4 = port_func2(ticker,df3)\n",
    "    return df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../data/midas_raw/midas_df.parquet\")\n",
    "cum_inv_df = pd.read_parquet(\"../data/midas_raw/midas_cum_inv_df.parquet\")\n",
    "tvdata = pd.read_parquet(\"../data/parquet/tvdata23.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_all = pd.DataFrame()\n",
    "for ticker in df.ticker.unique():\n",
    "    try:\n",
    "        port_temp = portfoy(ticker)\n",
    "        port_all = pd.concat([port_all, port_temp], axis=0, ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(ticker, e)\n",
    "port_all = port_all.query(\"ticker != 'ALTIN.S1'\")\n",
    "port_all.reset_index(drop=True, inplace=True)\n",
    "# port_all.to_parquet(\"../streamlit/portfolyo/port_all.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the conditions\n",
    "condition_ofsym = ((port_all['ticker'] == 'OFSYM') & (port_all['date'] >= '2023-08-16')) | (port_all['ticker'] != 'OFSYM')\n",
    "condition_adgyo = ((port_all['ticker'] == 'ADGYO') & (port_all['date'] >= '2023-09-21')) | (port_all['ticker'] != 'ADGYO')\n",
    "\n",
    "# Combine the conditions and filter the DataFrame\n",
    "port_all = port_all[condition_ofsym & condition_adgyo]\n",
    "\n",
    "selected_col = [\"date\",\"ticker\",\"h_q\",\"a_p_b\",'d_q_c',\"open\",\"close\",\"d_%\",'a_%', 'a_a_b', 't_v',\"d_r_p\", 'a_r_p',\"d_ur_p\", 'a_ur_p',\"d_p\",\"a_p\"]\n",
    "hisse_gunluk = port_all[selected_col]\n",
    "\n",
    "selected_col2 = [\"date\",\"ticker\",\"h_q\",\"a_p_b\",'d_q_c',\"open\",\"close\",\"d_%\",'a_%', 'd_a_b',\"d_a_s\", 't_v',\"d_r_p\", 'a_r_p',\"d_ur_p\", 'a_ur_p']\n",
    "gunluk_ozet_raw = port_all[selected_col2]\n",
    "\n",
    "# Group by business week\n",
    "gunluk_ozet = gunluk_ozet_raw.groupby(pd.Grouper(key=\"date\",freq='D')).agg({\n",
    "    \"d_a_b\": 'sum',\n",
    "    \"d_a_s\":'sum',\n",
    "    \"t_v\": 'sum',\n",
    "    \"d_r_p\": 'sum',\n",
    "    \"d_ur_p\": 'sum',\n",
    "    \"a_r_p\": 'sum',\n",
    "    \"a_ur_p\": 'sum',\n",
    "}).reset_index()\n",
    "gunluk_ozet = gunluk_ozet[gunluk_ozet[\"date\"].isin(tvdata[\"date\"].unique())]\n",
    "gunluk_ozet[\"d_a_c\"] = - gunluk_ozet[\"d_a_b\"] + gunluk_ozet[\"d_a_s\"]\n",
    "gunluk_ozet[\"d_a_c\"] = gunluk_ozet[\"d_a_c\"].round(2)\n",
    "gunluk_ozet[\"t_v\"] = gunluk_ozet[\"t_v\"].round(2)\n",
    "gunluk_ozet.insert(3,\"t_v_y\",gunluk_ozet[\"t_v\"].shift(1))\n",
    "gunluk_ozet.loc[0,\"t_v_y\"] = gunluk_ozet.loc[0,\"d_a_b\"]\n",
    "\n",
    "gunluk_ozet[\"d_r_p\"] = gunluk_ozet[\"d_r_p\"].round(2)\n",
    "gunluk_ozet[\"d_ur_p\"] = gunluk_ozet[\"d_ur_p\"].round(2)\n",
    "\n",
    "gunluk_ozet = gunluk_ozet.merge(cum_inv_df, on=\"date\", how=\"left\")\n",
    "gunluk_ozet.rename(columns={\"cum_inv\": \"a_inv\"}, inplace=True)\n",
    "gunluk_ozet.insert(9,\"d_inv\",gunluk_ozet[\"a_inv\"].diff())\n",
    "gunluk_ozet.loc[0,\"d_inv\"] = gunluk_ozet.loc[0,\"a_inv\"]\n",
    "gunluk_ozet[\"d_inv\"] = gunluk_ozet[\"d_inv\"].astype(int)\n",
    "\n",
    "gunluk_ozet.loc[1:,\"t_v_y\"] = gunluk_ozet.loc[1:,\"t_v_y\"] + gunluk_ozet.loc[1:,\"d_inv\"]\n",
    "gunluk_ozet.insert(4,\"d_%\",(round(gunluk_ozet[\"t_v\"] / gunluk_ozet[\"t_v_y\"],4) - 1) * 100)\n",
    "\n",
    "gunluk_ozet[\"d_b\"] = gunluk_ozet[\"d_inv\"] + (gunluk_ozet[\"d_a_c\"])\n",
    "gunluk_ozet[\"a_b\"] = gunluk_ozet[\"d_b\"].cumsum()\n",
    "\n",
    "gunluk_ozet[\"a_r_p\"] = gunluk_ozet[\"a_r_p\"].round(2)\n",
    "gunluk_ozet[\"a_ur_p\"] = gunluk_ozet[\"a_ur_p\"].round(2)\n",
    "gunluk_ozet[\"d_p\"] = gunluk_ozet[\"d_r_p\"] + gunluk_ozet[\"d_ur_p\"]\n",
    "gunluk_ozet[\"d_p_y\"] = round(gunluk_ozet[\"d_p\"] / gunluk_ozet[\"t_v\"],4) * 100\n",
    "\n",
    "# # gunluk_ozet.to_parquet(\"gunluk_ozet.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_col = [\"date\",\"ticker\",\"h_q\",\"a_p_b\",'d_q_c',\"open\",\"close\",\"d_%\",'a_%', 'd_a_b',\"d_a_s\", 't_v',\"d_r_p\", 'a_r_p',\"d_ur_p\", 'a_ur_p',\"d_p\",\"a_p\"]\n",
    "haftalık_data = port_all[selected_col]\n",
    "def business_week(date):\n",
    "    # If the date is a Monday, return the date itself.\n",
    "    if date.weekday() == 0:  \n",
    "        return date\n",
    "    # Otherwise, return the date of the nearest past Monday.\n",
    "    else:\n",
    "        return date - pd.Timedelta(days=date.weekday())\n",
    "\n",
    "# Group by business week\n",
    "haftalık_ozet = haftalık_data.groupby([haftalık_data['date'].apply(business_week)]).agg({\n",
    "    \"d_a_b\": 'sum',\n",
    "    \"d_a_s\":'sum',\n",
    "    \"t_v\": 'sum',\n",
    "    \"d_r_p\": 'sum',\n",
    "    \"d_ur_p\": 'sum',\n",
    "    \"a_r_p\": 'sum',\n",
    "    \"a_ur_p\": 'sum',\n",
    "}).reset_index()\n",
    "\n",
    "haftalık_ozet = haftalık_ozet[haftalık_ozet[\"date\"].isin(tvdata[\"date\"].unique())]\n",
    "haftalık_ozet[\"d_a_c\"] = - haftalık_ozet[\"d_a_b\"] + haftalık_ozet[\"d_a_s\"]\n",
    "haftalık_ozet[\"d_a_c\"] = haftalık_ozet[\"d_a_c\"].round(2)\n",
    "haftalık_ozet[\"t_v\"] = haftalık_ozet[\"t_v\"].round(2)\n",
    "haftalık_ozet.insert(3,\"t_v_y\",haftalık_ozet[\"t_v\"].shift(1))\n",
    "haftalık_ozet.loc[0,\"t_v_y\"] = haftalık_ozet.loc[0,\"d_a_b\"]\n",
    "\n",
    "haftalık_ozet[\"d_r_p\"] = haftalık_ozet[\"d_r_p\"].round(2)\n",
    "haftalık_ozet[\"d_ur_p\"] = haftalık_ozet[\"d_ur_p\"].round(2)\n",
    "\n",
    "haftalık_ozet = haftalık_ozet.merge(cum_inv_df, on=\"date\", how=\"left\")\n",
    "haftalık_ozet.rename(columns={\"cum_inv\": \"a_inv\"}, inplace=True)\n",
    "haftalık_ozet.insert(9,\"d_inv\",haftalık_ozet[\"a_inv\"].diff())\n",
    "haftalık_ozet.loc[0,\"d_inv\"] = haftalık_ozet.loc[0,\"a_inv\"]\n",
    "haftalık_ozet[\"d_inv\"] = haftalık_ozet[\"d_inv\"].astype(int)\n",
    "\n",
    "haftalık_ozet.loc[1:,\"t_v_y\"] = haftalık_ozet.loc[1:,\"t_v_y\"] + haftalık_ozet.loc[1:,\"d_inv\"]\n",
    "haftalık_ozet.insert(4,\"d_%\",(round(haftalık_ozet[\"t_v\"] / haftalık_ozet[\"t_v_y\"],4) - 1) * 100)\n",
    "\n",
    "haftalık_ozet[\"d_b\"] = haftalık_ozet[\"d_inv\"] + (haftalık_ozet[\"d_a_c\"])\n",
    "haftalık_ozet[\"a_b\"] = haftalık_ozet[\"d_b\"].cumsum()\n",
    "\n",
    "haftalık_ozet[\"a_r_p\"] = haftalık_ozet[\"a_r_p\"].round(2)\n",
    "haftalık_ozet[\"a_ur_p\"] = haftalık_ozet[\"a_ur_p\"].round(2)\n",
    "haftalık_ozet[\"d_p\"] = haftalık_ozet[\"d_r_p\"] + haftalık_ozet[\"d_ur_p\"]\n",
    "haftalık_ozet[\"d_p_y\"] = round(haftalık_ozet[\"d_p\"] / haftalık_ozet[\"t_v\"],4) * 100\n",
    "\n",
    "# haftalık_ozet\n",
    "# haftalık_ozet.to_parquet(\"haftalık_ozet.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'04-10-2023'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "now = datetime.now()\n",
    "if now.weekday() >= 5:  # 5: Saturday, 6: Sunday\n",
    "    days_to_subtract = now.weekday() - 4\n",
    "    today = now.date() - timedelta(days=days_to_subtract)\n",
    "    today_str = (now - timedelta(days=days_to_subtract)).strftime(\"%d-%m-%Y\")\n",
    "else:\n",
    "    if now.hour < 18:\n",
    "        today = now.date() - timedelta(days=1)\n",
    "        today_str = (now - timedelta(days=1)).strftime(\"%d-%m-%Y\")\n",
    "    else:\n",
    "        today = now.date()\n",
    "        today_str = now.strftime(\"%d-%m-%Y\")\n",
    "today_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "toplam_buyukluk = port_all.query(\"date == @today\").t_v.sum()\n",
    "gunluk_net = gunluk_ozet.query(\"date == @today\").d_p.values[0]\n",
    "gunluk_yuzde = gunluk_ozet.query(\"date == @today\").d_p_y.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'ADGYO', 'value': 1039.7},\n",
       " {'name': 'SDTTR', 'value': 5070.8},\n",
       " {'name': 'KLSER', 'value': 5236.0},\n",
       " {'name': 'ISGSY', 'value': 5481.0},\n",
       " {'name': 'TURSG', 'value': 6358.1},\n",
       " {'name': 'MGROS', 'value': 7442.3},\n",
       " {'name': 'ANSGR', 'value': 9036.4},\n",
       " {'name': 'MPARK', 'value': 11475.0},\n",
       " {'name': 'OSMEN', 'value': 11671.8},\n",
       " {'name': 'KAREL', 'value': 14805.0},\n",
       " {'name': 'ISCTR', 'value': 19461.4}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "son_hafta = gunluk_ozet[-7:]\n",
    "son_hafta.reset_index(drop=True, inplace=True)\n",
    "haftalik_net = (\n",
    "    son_hafta.iloc[-1][\"t_v\"] - son_hafta.iloc[0][\"t_v\"] - son_hafta[\"d_inv\"].sum()\n",
    ")\n",
    "haftalik_yuzde = round(\n",
    "    (1 - (son_hafta.iloc[-7][\"t_v\"] / son_hafta.iloc[-1][\"t_v\"])) * 100, 2\n",
    ")\n",
    "\n",
    "son_ay = gunluk_ozet[-30:]\n",
    "son_ay.reset_index(drop=True, inplace=True)\n",
    "aylik_net = son_ay.iloc[-1][\"t_v\"] - son_ay.iloc[0][\"t_v\"] - son_ay[\"d_inv\"].sum()\n",
    "aylik_yuzde = round(\n",
    "    (1 - (son_ay.iloc[0][\"t_v\"] / (son_ay.iloc[-1][\"t_v\"] - son_ay[\"d_inv\"].sum())))\n",
    "    * 100,\n",
    "    2,\n",
    ")\n",
    "\n",
    "son_gun = hisse_gunluk.query(\"date == @today\").sort_values(\n",
    "    by=\"t_v\", ascending=True\n",
    ")\n",
    "son_gun.dropna(how=\"any\", inplace=True)\n",
    "data_list = [\n",
    "    {\"name\": ticker, \"value\": round(value, 1)}\n",
    "    for ticker, value in son_gun[[\"ticker\", \"t_v\"]].values\n",
    "]\n",
    "data_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
